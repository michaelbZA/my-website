<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Finance Leadership in the AI Era on Michael Brunger</title><link>https://michaelbrunger.com/categories/finance-leadership-in-the-ai-era/</link><description>Recent content in Finance Leadership in the AI Era on Michael Brunger</description><image><title>Michael Brunger</title><url>https://michaelbrunger.com/site-feature-image.jpg</url><link>https://michaelbrunger.com/site-feature-image.jpg</link></image><generator>Hugo -- 0.146.7</generator><language>en-GB</language><lastBuildDate>Fri, 09 May 2025 14:44:55 +0100</lastBuildDate><atom:link href="https://michaelbrunger.com/categories/finance-leadership-in-the-ai-era/index.xml" rel="self" type="application/rss+xml"/><item><title>AI for Financial Forecasting and Planning</title><link>https://michaelbrunger.com/ai-financial-forecasting-planning/</link><pubDate>Thu, 31 Jul 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/ai-financial-forecasting-planning/</guid><description>Transform your financial planning and forecasting processes with AI technologies, balancing machine learning capabilities with human expertise.</description></item><item><title>Ethical Considerations in Financial AI</title><link>https://michaelbrunger.com/ethical-considerations-financial-ai/</link><pubDate>Thu, 24 Jul 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/ethical-considerations-financial-ai/</guid><description>Navigate the complex ethical landscape of AI implementation in finance, including bias, transparency, privacy and compliance concerns.</description><content:encoded><![CDATA[<h1 id="ethical-considerations-in-financial-ai">Ethical Considerations in Financial AI</h1>
<p><em>This is the third installment in my series &ldquo;Financial Leadership in the AI Era.&rdquo; If you&rsquo;re just joining, check out the <a href="link-to-first-post">first post</a> on separating AI hype from reality and the <a href="link-to-second-post">second post</a> on building your team&rsquo;s AI literacy.</em></p>
<h2 id="when-algorithms-make-financial-decisions">When Algorithms Make Financial Decisions</h2>
<p>Three months into my role as a finance manager, my team faced our first significant ethical dilemma with AI implementation. We were evaluating a vendor&rsquo;s AI solution for credit analysis that promised to increase approval rates while reducing default risk. The system showed impressive results in the demo, but when we dug deeper into how it made decisions, we discovered it was using postal codes as a significant factor—potentially serving as a proxy for demographic information that could lead to discriminatory outcomes.</p>
<p>This experience highlighted that as finance professionals implement AI, we take on new ethical responsibilities. The algorithms we deploy can affect people&rsquo;s financial lives in profound ways, from credit decisions to financial planning recommendations to fraud detection. And unlike traditional financial models with clear rules, many AI systems operate as &ldquo;black boxes&rdquo; with complex decision-making processes that can be difficult to explain.</p>
<p>According to a 2023 survey by the Financial Executives Research Foundation, 64% of finance leaders report being unprepared to address the ethical implications of AI in their operations (FERF, 2023). In this post, I&rsquo;ll share what I&rsquo;ve learned about navigating the ethical landscape of AI in finance, including practical frameworks we&rsquo;ve implemented in our department.</p>
<h2 id="algorithmic-bias-in-financial-decision-making">Algorithmic Bias in Financial Decision-Making</h2>
<p>Algorithmic bias occurs when an AI system produces systematically prejudiced outcomes. In finance, where decisions directly impact people&rsquo;s economic opportunities, such bias is particularly concerning.</p>
<h3 id="how-bias-enters-financial-ai-systems">How Bias Enters Financial AI Systems</h3>
<p>In my research and experience, I&rsquo;ve identified several common entry points for bias:</p>
<ol>
<li>
<p><strong>Historical Data Bias</strong>: When AI systems learn from historical data that contains human biases or reflects historical inequities, they can perpetuate and even amplify these patterns. For example, if lending decisions historically disfavored certain groups, an AI trained on this data may continue this discrimination, even if protected characteristics are removed.</p>
</li>
<li>
<p><strong>Proxy Variables</strong>: Even when sensitive variables (like race or gender) are excluded, AI systems may identify proxies—variables that correlate with protected characteristics. In our credit analysis example, postal codes served as potential proxies for demographic information.</p>
</li>
<li>
<p><strong>Sampling Bias</strong>: If training data overrepresents or underrepresents certain groups, the resulting model may perform poorly for underrepresented populations. The Federal Reserve Bank of New York found that AI lending models trained primarily on data from urban borrowers performed 5-10% worse when applied to rural borrowers (Federal Reserve Bank of NY, 2023).</p>
</li>
<li>
<p><strong>Feedback Loops</strong>: When AI systems influence future data collection, they can create reinforcing cycles. For instance, if an algorithm directs more fraud investigation resources toward certain customer segments, it may detect more fraud in those segments, seemingly confirming its original hypothesis.</p>
</li>
</ol>
<h3 id="real-world-consequences">Real-World Consequences</h3>
<p>The impact of algorithmic bias in finance is not theoretical. A 2023 study in the Journal of Finance found that algorithmic lending systems approved minority applicants at rates 9-14% lower than equally qualified white applicants across multiple financial institutions (Journal of Finance, 2023).</p>
<p>At our company, we conducted a retrospective analysis of a previously implemented collections prioritization algorithm and discovered it was disproportionately targeting small businesses in certain industries where women and minority ownership is higher, without corresponding evidence of higher risk.</p>
<h2 id="transparency-and-explainability-requirements">Transparency and Explainability Requirements</h2>
<p>When financial decisions are made or influenced by AI, both ethical considerations and increasing regulatory requirements demand that these decisions be explainable to stakeholders, including customers, regulators, and internal governance teams.</p>
<h3 id="the-explainability-challenge">The Explainability Challenge</h3>
<p>Financial AI systems range from highly transparent to nearly opaque:</p>
<ul>
<li><strong>Rules-based systems</strong> follow clear, understandable logic</li>
<li><strong>Simple machine learning models</strong> (like linear regression or decision trees) can be relatively transparent</li>
<li><strong>Complex models</strong> (like deep neural networks) may offer superior performance but provide limited insight into their decision-making</li>
</ul>
<p>The European Union&rsquo;s AI Act, finalized in 2023, establishes that AI systems used in &ldquo;high-risk&rdquo; domains—explicitly including credit scoring and other financial services—must provide &ldquo;appropriate levels of transparency&rdquo; and human oversight (European Commission, 2023).</p>
<p>Similarly, in the United States, existing regulations like the Equal Credit Opportunity Act (ECOA) and Fair Credit Reporting Act (FCRA) require that consumers receive explanations for adverse credit actions—requirements that extend to algorithmically-derived decisions.</p>
<h3 id="practical-approaches-to-explainability">Practical Approaches to Explainability</h3>
<p>To address explainability challenges, we&rsquo;ve implemented several practices:</p>
<ol>
<li>
<p><strong>Explainability by Design</strong>: When evaluating AI solutions, we now explicitly score vendors on their ability to explain how their systems arrive at recommendations. Simple models with clear factor weights often win over marginally more accurate &ldquo;black box&rdquo; approaches.</p>
</li>
<li>
<p><strong>Local Interpretable Model-Agnostic Explanations (LIME)</strong>: For more complex models, we&rsquo;ve begun using techniques like LIME to generate approximations of how specific decisions were made. This allows us to provide factor-based explanations for individual cases.</p>
</li>
<li>
<p><strong>Confidence Metrics</strong>: We require all AI recommendations to include confidence levels and the factors that most influenced the confidence assessment.</p>
</li>
<li>
<p><strong>Human Review Thresholds</strong>: We&rsquo;ve established confidence thresholds below which human review is automatically triggered before decisions are finalized.</p>
</li>
</ol>
<p>According to KPMG&rsquo;s 2024 AI Governance Survey, organizations with structured explainability requirements report 27% fewer compliance issues when implementing AI in regulated functions like finance (KPMG, 2024).</p>
<h2 id="data-privacy-concerns-in-ai-powered-finance">Data Privacy Concerns in AI-Powered Finance</h2>
<p>AI systems typically require substantial data to train and operate effectively. This creates unique privacy challenges for finance departments handling sensitive personal and business financial information.</p>
<h3 id="key-privacy-considerations">Key Privacy Considerations</h3>
<p>Through our implementation experiences and research, we&rsquo;ve identified several critical privacy considerations:</p>
<ol>
<li>
<p><strong>Data Minimization</strong>: Determining the minimum data necessary for the AI to function effectively. When evaluating a cash flow forecasting solution, we found that transaction-level data with customer identifiers could be replaced with aggregated data without sacrificing accuracy.</p>
</li>
<li>
<p><strong>Purpose Limitation</strong>: Ensuring data collected for one purpose isn&rsquo;t repurposed for AI training without appropriate consent. We discovered that customer data collected for service delivery was being used to train an AI marketing model without explicit consent.</p>
</li>
<li>
<p><strong>Retention Policies</strong>: Establishing clear timelines for data retention based on operational necessity rather than potential future AI applications.</p>
</li>
<li>
<p><strong>Right to Explanation</strong>: Providing mechanisms for individuals to understand how their data influences AI decisions affecting them.</p>
</li>
<li>
<p><strong>Cross-Border Data Flows</strong>: Understanding how AI solutions may transfer data across jurisdictions with different privacy standards.</p>
</li>
</ol>
<p>The financial industry faces particularly stringent requirements. The Gramm-Leach-Bliley Act in the US and GDPR in Europe both place significant restrictions on how financial institutions can use customer data, with GDPR specifically addressing automated decision-making rights (GDPR Article 22).</p>
<h3 id="managing-third-party-ai-risks">Managing Third-Party AI Risks</h3>
<p>A significant challenge we&rsquo;ve encountered is evaluating how third-party AI vendors handle data privacy. We&rsquo;ve developed a vendor assessment framework that includes questions like:</p>
<ul>
<li>Does the vendor use client data to train models that benefit other clients?</li>
<li>What anonymization techniques are employed to protect sensitive information?</li>
<li>How does the vendor define and identify personal information?</li>
<li>What controls prevent model inversion attacks that could reconstruct training data?</li>
</ul>
<p>According to a 2023 survey by the American Institute of CPAs, 42% of organizations using third-party AI solutions in finance functions could not fully verify how their data was being used by vendors (AICPA, 2023).</p>
<h2 id="ethical-frameworks-for-ai-implementation">Ethical Frameworks for AI Implementation</h2>
<p>To systematize our approach to ethical AI decision-making, we&rsquo;ve adopted a modified version of the framework recommended by the Organisation for Economic Co-operation and Development (OECD, 2023), customized for financial applications:</p>
<h3 id="our-financial-ai-ethics-framework">Our Financial AI Ethics Framework</h3>
<ol>
<li>
<p><strong>Beneficence</strong>: Does the AI application create genuine value for customers and stakeholders? We measure this through:</p>
<ul>
<li>Quantifiable customer benefits (time saved, improved outcomes)</li>
<li>Enhanced financial inclusion</li>
<li>Increased transparency in financial processes</li>
</ul>
</li>
<li>
<p><strong>Non-maleficence</strong>: Does the application avoid causing harm? We evaluate:</p>
<ul>
<li>Potential for discriminatory outcomes</li>
<li>Creation of financial vulnerabilities</li>
<li>Reinforcement of existing inequities</li>
</ul>
</li>
<li>
<p><strong>Autonomy</strong>: Does the application respect human agency? We assess:</p>
<ul>
<li>Clarity about when decisions are AI-influenced</li>
<li>Options for human review</li>
<li>Ability to contest automated decisions</li>
</ul>
</li>
<li>
<p><strong>Justice</strong>: Does the application promote fairness? We examine:</p>
<ul>
<li>Equal performance across demographic groups</li>
<li>Equal access to benefits</li>
<li>Fair distribution of risks and rewards</li>
</ul>
</li>
<li>
<p><strong>Explicability</strong>: Can the application&rsquo;s decisions be meaningfully explained? We require:</p>
<ul>
<li>Documentation of model factors and weights</li>
<li>Case-specific explanation capabilities</li>
<li>Transparency about confidence levels and limitations</li>
</ul>
</li>
</ol>
<p>For each AI implementation, we score the proposal against these five dimensions on a scale of 1-5. Any dimension scoring below 3 triggers additional review and mitigation requirements before approval.</p>
<h2 id="compliance-considerations-when-implementing-ai-solutions">Compliance Considerations When Implementing AI Solutions</h2>
<p>Beyond ethical considerations, finance departments must navigate an evolving regulatory landscape around AI. Based on our experience and consultation with compliance experts, here are the key compliance areas finance leaders should consider:</p>
<h3 id="regulatory-framework-for-financial-ai">Regulatory Framework for Financial AI</h3>
<ol>
<li>
<p><strong>Non-discrimination Requirements</strong>:</p>
<ul>
<li>Equal Credit Opportunity Act (US)</li>
<li>Fair Housing Act (US)</li>
<li>Various non-discrimination directives (EU)</li>
<li>Consumer Financial Protection Bureau&rsquo;s focus on algorithmic fairness</li>
</ul>
</li>
<li>
<p><strong>Explanation Requirements</strong>:</p>
<ul>
<li>Fair Credit Reporting Act (US)</li>
<li>GDPR Article 22 (EU)</li>
<li>Consumer Financial Protection Bureau guidance on adverse action notices</li>
</ul>
</li>
<li>
<p><strong>Data Protection Requirements</strong>:</p>
<ul>
<li>Gramm-Leach-Bliley Act (US)</li>
<li>General Data Protection Regulation (EU)</li>
<li>California Consumer Privacy Act (California)</li>
<li>State-level privacy laws</li>
</ul>
</li>
<li>
<p><strong>Model Risk Management</strong>:</p>
<ul>
<li>Federal Reserve SR 11-7 (US)</li>
<li>OCC Bulletin 2011-12 (US)</li>
<li>European Banking Authority Guidelines on ICT Risk Assessment</li>
</ul>
</li>
<li>
<p><strong>Emerging AI-Specific Regulations</strong>:</p>
<ul>
<li>EU AI Act (effective 2025)</li>
<li>NIST AI Risk Management Framework (US)</li>
<li>Colorado&rsquo;s law on insurance AI (effective 2023)</li>
</ul>
</li>
</ol>
<p>According to Deloitte&rsquo;s 2024 Financial Services Regulatory Outlook, regulators across jurisdictions are increasingly focusing on financial institutions&rsquo; governance of AI systems, with examination emphasis on documentation of development processes, testing for bias, and ongoing monitoring (Deloitte, 2024).</p>
<h3 id="practical-compliance-approaches">Practical Compliance Approaches</h3>
<p>To address these requirements, we&rsquo;ve implemented several compliance practices:</p>
<ol>
<li>
<p><strong>Model Documentation</strong>: Creating comprehensive documentation of model development, including design decisions, data sources, training methodologies, and testing results.</p>
</li>
<li>
<p><strong>Fairness Testing</strong>: Conducting statistical tests for disparate impact across protected classes before deployment.</p>
</li>
<li>
<p><strong>Ongoing Monitoring</strong>: Establishing key performance indicators to detect model drift or emerging bias during operation.</p>
</li>
<li>
<p><strong>Regulatory Change Management</strong>: Designating team members responsible for tracking evolving AI regulations in our operating jurisdictions.</p>
</li>
<li>
<p><strong>Audit Trails</strong>: Implementing logging systems to record all AI-influenced decisions for potential regulatory examination.</p>
</li>
</ol>
<p>According to EY&rsquo;s 2023 Global Financial Services Risk Survey, organizations with formal AI governance frameworks report 35% fewer regulatory findings related to their algorithmic systems (EY, 2023).</p>
<h2 id="building-ethical-guidelines-for-your-finance-team">Building Ethical Guidelines for Your Finance Team</h2>
<p>Converting these ethical and compliance considerations into practical guidance for finance teams is challenging. Here&rsquo;s the approach we&rsquo;ve taken to operationalize ethical AI principles:</p>
<h3 id="our-ethical-ai-implementation-process">Our Ethical AI Implementation Process</h3>
<ol>
<li>
<p><strong>Pre-Implementation Assessment</strong>:</p>
<ul>
<li>Complete ethics assessment using our five-dimension framework</li>
<li>Conduct disparate impact analysis using historical data</li>
<li>Document explainability approach</li>
<li>Define human oversight mechanisms</li>
</ul>
</li>
<li>
<p><strong>Implementation Requirements</strong>:</p>
<ul>
<li>Establish monitoring metrics for bias detection</li>
<li>Create transparent documentation of decision factors</li>
<li>Define confidence thresholds for automation vs. human review</li>
<li>Develop customer-friendly explanation templates</li>
</ul>
</li>
<li>
<p><strong>Post-Implementation Review</strong>:</p>
<ul>
<li>Conduct quarterly fairness audits</li>
<li>Review explanation quality and comprehensibility</li>
<li>Assess customer feedback on AI-influenced decisions</li>
<li>Evaluate performance across customer segments</li>
</ul>
</li>
<li>
<p><strong>Continuous Governance</strong>:</p>
<ul>
<li>Monthly ethics committee review of edge cases</li>
<li>Quarterly model performance reviews</li>
<li>Annual comprehensive ethical reassessment</li>
<li>Ongoing regulatory compliance monitoring</li>
</ul>
</li>
</ol>
<p>We&rsquo;ve found that embedding ethics reviews into existing risk and governance processes rather than creating separate workflows leads to better integration and compliance.</p>
<h2 id="case-study-our-ethical-dilemma-with-accounts-receivable-ai">Case Study: Our Ethical Dilemma with Accounts Receivable AI</h2>
<p>To illustrate these principles in action, I&rsquo;ll share how we addressed an ethical challenge with an accounts receivable collection prioritization system we recently evaluated.</p>
<p>The system promised to identify which overdue accounts to prioritize for collection efforts based on likelihood of payment. Initial results were impressive, showing a projected 23% increase in collection effectiveness.</p>
<p>However, our ethics review identified several concerns:</p>
<ol>
<li>The system heavily weighted past payment history, potentially disadvantaging newer customers with limited history</li>
<li>Small businesses were flagged for aggressive collection at higher rates than larger businesses with similar risk profiles</li>
<li>The explanation capabilities were limited to general factors rather than case-specific reasoning</li>
</ol>
<p>Rather than rejecting the system outright, we worked with the vendor to:</p>
<ol>
<li>Adjust the model to reduce the weight of payment history for newer customers</li>
<li>Implement business-size normalization to ensure fair treatment across company sizes</li>
<li>Enhance explanation capabilities to provide specific factors for each case</li>
<li>Add a human review requirement for any first-time collection escalation</li>
</ol>
<p>The revised system still delivered a 19% improvement in collection effectiveness—slightly lower than the original projection, but with significantly reduced ethical risks.</p>
<h2 id="my-learning-so-far">My Learning So Far</h2>
<p>The most profound insight from our AI ethics journey has been recognizing that ethical considerations aren&rsquo;t separate from business performance—they&rsquo;re integral to sustainable success. Systems that make fair, explainable decisions build trust, reduce regulatory risk, and ultimately deliver more stable long-term performance.</p>
<p>I&rsquo;ve also learned that ethics can&rsquo;t be outsourced to vendors or compliance teams. As finance leaders implementing AI, we have a responsibility to understand the ethical implications of the systems we deploy and to actively govern them throughout their lifecycle.</p>
<p>In my next post, I&rsquo;ll explore &ldquo;AI for Financial Forecasting and Planning,&rdquo; examining how machine learning is transforming our ability to predict financial outcomes and plan for multiple scenarios. I&rsquo;ll share practical examples from our implementation of AI-assisted forecasting tools and the lessons we&rsquo;ve learned about integrating algorithmic and human judgment.</p>
<h2 id="your-turn">Your Turn</h2>
<p>I&rsquo;d love to hear about your experiences with ethical considerations in financial AI:</p>
<ul>
<li>What ethical challenges have you encountered when implementing AI in finance functions?</li>
<li>How does your organization evaluate AI systems for fairness and bias?</li>
<li>What governance structures have you found effective for ongoing ethical oversight?</li>
</ul>
<p>Share your thoughts in the comments below or reach out directly.</p>
<hr>
<h2 id="sources">Sources</h2>
<ul>
<li>American Institute of CPAs (AICPA). (2023). <em>Third-Party Risk Management in the Age of AI</em>. AICPA.</li>
<li>Deloitte. (2024). <em>Financial Services Regulatory Outlook</em>. Deloitte LLP.</li>
<li>European Commission. (2023). <em>Artificial Intelligence Act Final Text</em>. EC.</li>
<li>Ernst &amp; Young (EY). (2023). <em>Global Financial Services Risk Survey</em>. EY.</li>
<li>Federal Reserve Bank of New York. (2023). <em>Staff Report: Machine Learning and Consumer Lending</em>. FRBNY.</li>
<li>Financial Executives Research Foundation (FERF). (2023). <em>Ethical AI in Finance Survey</em>. FERF.</li>
<li>Journal of Finance. (2023). <em>Algorithmic Bias in Mortgage Lending</em>. American Finance Association.</li>
<li>KPMG. (2024). <em>AI Governance Survey</em>. KPMG International.</li>
<li>Organisation for Economic Co-operation and Development (OECD). (2023). <em>AI Principles for Responsible Stewardship of Trustworthy AI</em>. OECD.</li>
</ul>
]]></content:encoded></item><item><title>The CFO's AI Strategy Playbook</title><link>https://michaelbrunger.com/cfo-ai-strategy-playbook/</link><pubDate>Sat, 19 Jul 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/cfo-ai-strategy-playbook/</guid><description>A comprehensive framework for CFOs and finance leaders to develop and implement a strategic AI roadmap for finance transformation.</description></item><item><title>Building Your Finance Team's AI Literacy</title><link>https://michaelbrunger.com/building-finance-team-ai-literacy/</link><pubDate>Thu, 17 Jul 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/building-finance-team-ai-literacy/</guid><description>A comprehensive guide to developing essential AI knowledge across your finance team, with practical learning paths and assessment frameworks.</description><content:encoded><![CDATA[<h1 id="building-your-finance-teams-ai-literacy">Building Your Finance Team&rsquo;s AI Literacy</h1>
<p><em>This is the second installment in my series &ldquo;Financial Leadership in the AI Era.&rdquo; If you missed it, check out the <a href="link-to-first-post">previous post</a> where we explored separating AI hype from reality in finance departments.</em></p>
<h2 id="the-literacy-gap-in-finance">The Literacy Gap in Finance</h2>
<p>Six weeks into my role as a finance manager, I&rsquo;ve identified a significant challenge: the varying levels of AI literacy within our team. During a recent discussion about potentially implementing an AI-assisted forecasting tool, I noticed reactions ranging from unrealistic enthusiasm (&ldquo;This will solve all our forecasting problems!&rdquo;) to deep skepticism (&ldquo;I don&rsquo;t trust any black-box system&rdquo;) to anxiety (&ldquo;Will this replace my job?&rdquo;).</p>
<p>This experience isn&rsquo;t unique. According to a 2023 survey by the Association of International Certified Professional Accountants (AICPA), 78% of finance leaders cited &ldquo;inadequate understanding of AI capabilities and limitations among team members&rdquo; as a major barrier to effective AI implementation (AICPA, 2023).</p>
<p>The literacy gap creates real problems: it leads to poor technology decisions, ineffective implementation, resistance to valuable tools, and missed opportunities to enhance finance operations. Building a shared foundation of AI literacy has become my priority before we attempt any significant AI initiatives.</p>
<h2 id="essential-ai-concepts-finance-professionals-need-to-understand">Essential AI Concepts Finance Professionals Need to Understand</h2>
<p>After consulting with both technology experts and finance leaders who&rsquo;ve successfully implemented AI, I&rsquo;ve identified the core concepts that every finance professional should understand:</p>
<h3 id="1-the-ai-spectrum-from-automation-to-intelligence">1. The AI Spectrum: From Automation to Intelligence</h3>
<p>Finance teams often conflate basic automation with true AI capabilities. Understanding the spectrum is essential:</p>
<ul>
<li><strong>Rules-based Automation</strong>: Predefined instructions for handling specific scenarios (e.g., basic AP matching)</li>
<li><strong>Robotic Process Automation (RPA)</strong>: Software that mimics human actions for repetitive tasks (e.g., data extraction from invoices)</li>
<li><strong>Machine Learning</strong>: Systems that learn from data to identify patterns and make predictions (e.g., anomaly detection in expenses)</li>
<li><strong>Natural Language Processing</strong>: Ability to understand and generate human language (e.g., extracting key terms from contracts)</li>
<li><strong>Deep Learning</strong>: Advanced neural networks that can handle complex, unstructured data (e.g., forecasting models that incorporate multiple data sources)</li>
</ul>
<p>Understanding this spectrum helps finance teams set realistic expectations and choose appropriate solutions for specific challenges.</p>
<h3 id="2-the-data-foundation">2. The Data Foundation</h3>
<p>Many finance teams underestimate the importance of data quality for AI success. Essential concepts include:</p>
<ul>
<li><strong>Data Requirements</strong>: Different AI applications have different data needs in terms of volume, variety, and quality</li>
<li><strong>Data Cleaning</strong>: The process of identifying and correcting errors or inconsistencies in datasets</li>
<li><strong>Training Data</strong>: The historical information AI systems learn from</li>
<li><strong>Bias in Data</strong>: How historical biases in data can be perpetuated or amplified by AI systems</li>
<li><strong>Data Governance</strong>: Policies and procedures that ensure data accuracy, consistency, and security</li>
</ul>
<p>According to IBM&rsquo;s Institute for Business Value, organizations with strong data governance are 83% more likely to exceed expectations in their AI initiatives (IBM, 2023).</p>
<h3 id="3-how-ai-makes-decisions">3. How AI Makes &ldquo;Decisions&rdquo;</h3>
<p>Demystifying AI decision-making processes helps build appropriate trust:</p>
<ul>
<li><strong>Probabilistic vs. Deterministic</strong>: Understanding that many AI systems provide probability-based recommendations rather than certain answers</li>
<li><strong>Pattern Recognition</strong>: How systems identify meaningful patterns in large datasets</li>
<li><strong>Explainability</strong>: The degree to which AI decisions can be understood and explained by humans</li>
<li><strong>Confidence Levels</strong>: How to interpret confidence scores in AI outputs</li>
<li><strong>Edge Cases</strong>: Understanding situations where AI performance may degrade</li>
</ul>
<p>A McKinsey study found that finance teams with basic understanding of AI decision-making were 45% more likely to successfully implement AI solutions compared to teams without this knowledge (McKinsey, 2024).</p>
<h3 id="4-ai-ethics-and-governance">4. AI Ethics and Governance</h3>
<p>As stewards of financial data and decision-making, finance teams need to understand:</p>
<ul>
<li><strong>Algorithmic Bias</strong>: How bias can enter AI systems and impact financial decisions</li>
<li><strong>Transparency Requirements</strong>: Regulatory and ethical standards for AI transparency</li>
<li><strong>Human Oversight</strong>: Best practices for maintaining appropriate human supervision</li>
<li><strong>Audit Trails</strong>: Requirements for documenting AI-influenced decisions</li>
<li><strong>Model Drift</strong>: How AI systems can become less accurate over time without proper oversight</li>
</ul>
<p>The Financial Stability Board&rsquo;s 2023 report emphasizes that financial institutions using AI must maintain clear accountability and governance frameworks regardless of algorithm complexity (Financial Stability Board, 2023).</p>
<h2 id="developing-a-common-ai-vocabulary">Developing a Common AI Vocabulary</h2>
<p>One of the first challenges I encountered was the lack of shared language around AI. Technical teams would use jargon like &ldquo;supervised learning&rdquo; or &ldquo;feature engineering,&rdquo; while finance team members struggled to articulate their requirements in terms the tech team could understand.</p>
<p>To address this, I created a simple &ldquo;AI in Finance Glossary&rdquo; for our department. Here are some key terms we&rsquo;ve included:</p>
<ul>
<li><strong>Algorithm</strong>: A process or set of rules followed to solve a problem or perform a task</li>
<li><strong>Artificial Intelligence (AI)</strong>: Technology that enables computers to perform tasks that typically require human intelligence</li>
<li><strong>Machine Learning (ML)</strong>: A subset of AI where systems learn from data to improve performance</li>
<li><strong>Training</strong>: The process of teaching an AI model using historical data</li>
<li><strong>Model</strong>: A specific representation of patterns learned from data</li>
<li><strong>Feature</strong>: An individual measurable property used as input for a machine learning algorithm</li>
<li><strong>Supervised Learning</strong>: Training an algorithm on labeled data to predict outcomes</li>
<li><strong>Unsupervised Learning</strong>: Finding patterns in unlabeled data</li>
<li><strong>Confidence Score</strong>: A measure of how certain an AI system is about its prediction</li>
<li><strong>Model Drift</strong>: The degradation of model performance over time as conditions change</li>
</ul>
<p>Having this shared vocabulary has significantly improved our discussions with both vendors and IT partners. The CFA Institute offers an excellent expanded glossary specifically for finance professionals that we&rsquo;ve drawn from (CFA Institute, 2023).</p>
<h2 id="training-resources-and-approaches-for-different-team-roles">Training Resources and Approaches for Different Team Roles</h2>
<p>Not everyone on a finance team needs the same level of AI knowledge. I&rsquo;ve developed a tiered approach based on roles:</p>
<h3 id="for-all-finance-team-members-foundational-literacy">For All Finance Team Members: Foundational Literacy</h3>
<p>Everyone needs to understand basic concepts and develop appropriate confidence in working with AI-assisted systems:</p>
<ul>
<li><strong>Resource</strong>: LinkedIn Learning&rsquo;s &ldquo;AI for Non-Technical Professionals&rdquo; (2 hours)</li>
<li><strong>Approach</strong>: Monthly lunch-and-learn sessions discussing real-world finance AI applications</li>
<li><strong>Assessment</strong>: Basic quiz on AI terminology and capabilities</li>
</ul>
<h3 id="for-finance-analysts-and-managers-intermediate-knowledge">For Finance Analysts and Managers: Intermediate Knowledge</h3>
<p>Those who will be specifying requirements or interpreting AI outputs need deeper understanding:</p>
<ul>
<li><strong>Resources</strong>:
<ul>
<li>Coursera&rsquo;s &ldquo;AI for Business&rdquo; specialization by University of Pennsylvania (12-15 hours)</li>
<li>Harvard Business Review&rsquo;s &ldquo;AI Basics for Business&rdquo; series</li>
</ul>
</li>
<li><strong>Approach</strong>: Hands-on workshops with sample data and simple AI tools</li>
<li><strong>Assessment</strong>: Case study analysis of AI implementation in a finance context</li>
</ul>
<h3 id="for-finance-technology-specialists-advanced-understanding">For Finance Technology Specialists: Advanced Understanding</h3>
<p>Team members who will serve as bridges between finance and technical teams require more technical knowledge:</p>
<ul>
<li><strong>Resources</strong>:
<ul>
<li>Google&rsquo;s &ldquo;Machine Learning Crash Course&rdquo; (15-20 hours)</li>
<li>DataCamp&rsquo;s &ldquo;Machine Learning for Finance&rdquo; track</li>
</ul>
</li>
<li><strong>Approach</strong>: Paired learning with data science team members on real projects</li>
<li><strong>Assessment</strong>: Collaborative project applying an AI solution to a finance problem</li>
</ul>
<p>According to Deloitte&rsquo;s 2023 Global Finance Skills Survey, organizations that implement role-based AI training see 37% higher satisfaction with AI implementations compared to those with one-size-fits-all approaches (Deloitte, 2023).</p>
<h2 id="creating-a-learning-roadmap">Creating a Learning Roadmap</h2>
<p>Based on my experience and research, I&rsquo;ve created a six-month learning roadmap for our finance team:</p>
<h3 id="month-1-awareness-building">Month 1: Awareness Building</h3>
<ul>
<li>AI foundations workshop for all team members</li>
<li>Introduction to the AI vocabulary guide</li>
<li>Assessment of current knowledge and attitudes</li>
</ul>
<h3 id="month-2-concept-exploration">Month 2: Concept Exploration</h3>
<ul>
<li>Focused sessions on data quality and governance</li>
<li>Case study reviews of successful finance AI implementations</li>
<li>Introduction to ethical considerations</li>
</ul>
<h3 id="month-3-hands-on-exposure">Month 3: Hands-On Exposure</h3>
<ul>
<li>Demonstration of AI tools already in use in the organization</li>
<li>Simple exercises with pre-built AI models</li>
<li>Discussion of how existing processes could be enhanced</li>
</ul>
<h3 id="month-4-application-to-current-challenges">Month 4: Application to Current Challenges</h3>
<ul>
<li>Identification of potential use cases within each team</li>
<li>Analysis of data readiness for identified use cases</li>
<li>Development of evaluation criteria for potential solutions</li>
</ul>
<h3 id="month-5-vendor-evaluation-skills">Month 5: Vendor Evaluation Skills</h3>
<ul>
<li>How to assess AI vendor claims</li>
<li>Questions to ask during demonstrations</li>
<li>Frameworks for comparing solutions</li>
</ul>
<h3 id="month-6-implementation-planning">Month 6: Implementation Planning</h3>
<ul>
<li>Change management considerations</li>
<li>Success metrics development</li>
<li>Building an AI implementation roadmap</li>
</ul>
<p>According to PwC&rsquo;s Finance Effectiveness Benchmark Report, organizations with structured AI learning programs achieve 31% higher ROI on their AI investments in finance functions (PwC, 2023).</p>
<h2 id="how-to-assess-your-teams-current-ai-readiness">How to Assess Your Team&rsquo;s Current AI Readiness</h2>
<p>Before implementing any learning program, it&rsquo;s important to assess where your team stands currently. I developed a simple assessment framework with three components:</p>
<h3 id="1-knowledge-assessment">1. Knowledge Assessment</h3>
<p>A brief survey to gauge understanding of key concepts:</p>
<ul>
<li>Basic terminology comprehension</li>
<li>Understanding of AI capabilities and limitations</li>
<li>Familiarity with data concepts</li>
</ul>
<h3 id="2-skills-inventory">2. Skills Inventory</h3>
<p>Identifying existing relevant skills:</p>
<ul>
<li>Data analysis capabilities</li>
<li>Experience with automation tools</li>
<li>Process improvement expertise</li>
<li>Change management experience</li>
</ul>
<h3 id="3-attitude-evaluation">3. Attitude Evaluation</h3>
<p>Understanding emotional and psychological readiness:</p>
<ul>
<li>Comfort level with technology change</li>
<li>Trust in algorithmic decision support</li>
<li>Concerns about job impact</li>
<li>Interest in developing new skills</li>
</ul>
<p>When we conducted this assessment with our team, we discovered surprising insights: while technical knowledge was indeed limited, we had strong foundations in data analysis and process improvement that would transfer well to AI implementation. The biggest gaps were in understanding how AI systems make decisions and in confidence evaluating vendor claims.</p>
<h2 id="early-results-from-our-learning-journey">Early Results from Our Learning Journey</h2>
<p>Two months into our AI literacy initiative, we&rsquo;re seeing promising signs:</p>
<ul>
<li>Team members are asking more sophisticated questions about AI capabilities</li>
<li>Discussions with vendors are more productive and focused</li>
<li>Two team members have identified potential AI use cases in their areas</li>
<li>Anxiety about AI has decreased as understanding has increased</li>
</ul>
<p>The most significant shift has been from viewing AI as either a threat or a silver bullet to seeing it as a tool with specific strengths and limitations that can enhance our existing processes.</p>
<h2 id="my-learning-so-far">My Learning So Far</h2>
<p>The biggest surprise in my AI literacy journey has been realizing how much finance expertise is actually required for successful AI implementation. Far from being replaced by technology, finance professionals with AI literacy become more valuable because they can apply domain knowledge to shape how AI is used.</p>
<p>I&rsquo;ve also learned that building AI literacy is as much about change management as it is about technical education. Addressing concerns, building confidence, and creating safe spaces for experimentation have been just as important as explaining technical concepts.</p>
<p>In my next post, I&rsquo;ll explore &ldquo;Ethical Considerations in Financial AI,&rdquo; examining how finance teams can ensure AI implementations align with ethical standards and regulatory requirements. I&rsquo;ll share the framework we&rsquo;re developing to evaluate ethical implications of AI decisions in our finance department.</p>
<h2 id="your-turn">Your Turn</h2>
<p>I&rsquo;d love to hear about your experiences with AI literacy in finance teams:</p>
<ul>
<li>What approaches have you found effective for building AI understanding?</li>
<li>Which concepts do finance professionals find most challenging?</li>
<li>What resources have you found most valuable?</li>
</ul>
<p>Share your thoughts in the comments below or reach out directly.</p>
<hr>
<h2 id="sources">Sources</h2>
<ul>
<li>Association of International Certified Professional Accountants (AICPA). (2023). <em>Finance Function Digital Transformation Survey</em>. AICPA.</li>
<li>CFA Institute. (2023). <em>Artificial Intelligence in Investment Management: A Practical Guide</em>. CFA Institute Research Foundation.</li>
<li>Deloitte. (2023). <em>Global Finance Skills Survey</em>. Deloitte LLP.</li>
<li>Financial Stability Board. (2023). <em>Artificial Intelligence and Machine Learning in Financial Services</em>. FSB.</li>
<li>IBM Institute for Business Value. (2023). <em>The AI Data Imperative</em>. IBM.</li>
<li>McKinsey &amp; Company. (2024). <em>Building AI Capabilities in Finance Functions</em>. McKinsey Digital.</li>
<li>PwC. (2023). <em>Finance Effectiveness Benchmark Report</em>. PricewaterhouseCoopers LLP.</li>
</ul>
]]></content:encoded></item><item><title>Financial Leadership in the AI Era: Series Introduction</title><link>https://michaelbrunger.com/financial-leadership-ai-era-introduction/</link><pubDate>Tue, 15 Jul 2025 00:00:00 +0000</pubDate><guid>https://michaelbrunger.com/financial-leadership-ai-era-introduction/</guid><description>Introduction to a comprehensive series exploring how AI is transforming finance leadership and providing practical guidance for finance professionals.</description><content:encoded><![CDATA[<h1 id="financial-leadership-in-the-ai-era-a-journey-of-discovery">Financial Leadership in the AI Era: A Journey of Discovery</h1>
<p><em>Welcome to my new blog series where I&rsquo;ll be documenting my learning journey as a finance manager navigating the evolving landscape of AI in finance.</em></p>
<h2 id="why-this-series">Why This Series?</h2>
<p>Two weeks ago, I stepped into a new role as a finance manager. Like many professionals in finance today, I&rsquo;m facing a rapidly changing environment where artificial intelligence is no longer just a buzzword but an increasingly important part of our toolkit. Rather than pretending to have all the answers, I&rsquo;ve decided to learn in public and bring you along for the journey.</p>
<p>This series isn&rsquo;t about presenting myself as an AI expert—quite the opposite. It&rsquo;s about being transparent about the challenges, discoveries, and practical insights I gain as I navigate the intersection of financial leadership and artificial intelligence. By sharing my learning process, I hope to create a resource that feels authentic and accessible to other finance professionals who may be on similar paths.</p>
<h2 id="what-to-expect">What to Expect</h2>
<p>Over the coming months, I&rsquo;ll be publishing regular posts covering everything from separating AI hype from reality to building AI literacy in finance teams, ethical considerations, practical applications in forecasting and operations, change management, ROI analysis, and the evolving skill requirements for finance leaders.</p>
<p>Each post will combine:</p>
<ul>
<li>My firsthand experiences implementing or evaluating AI solutions</li>
<li>Research and insights from trusted sources</li>
<li>Practical frameworks and approaches you can apply</li>
<li>Honest reflections on successes and failures</li>
</ul>
<p>I believe in the power of learning through doing, so I&rsquo;ll be sharing real examples from my own work (anonymized where necessary) and concrete steps you can take to advance your own journey with AI in finance.</p>
<h2 id="my-background-and-approach">My Background and Approach</h2>
<p>Before diving in, a bit about me: I&rsquo;ve spent the past [X] years in finance roles across [brief background]. While I have experience with [relevant experience], AI integration is a newer territory that I&rsquo;m actively exploring.</p>
<p>My approach to AI isn&rsquo;t about replacing human judgment or chasing every shiny new technology. Instead, I&rsquo;m focused on finding the practical, high-value applications that genuinely enhance our work as finance professionals. I believe the most successful AI implementations in finance will be those that augment rather than replace our expertise, freeing us to focus on the strategic work that requires human creativity and judgment.</p>
<h2 id="join-the-conversation">Join the Conversation</h2>
<p>This isn&rsquo;t meant to be a one-way broadcast. I invite you to share your own experiences, challenge my assumptions, suggest topics for future posts, and contribute to building a community of finance professionals who are thoughtfully navigating the AI revolution.</p>
<p>Whether you&rsquo;re a finance leader looking to enhance your team&rsquo;s capabilities, an individual contributor wanting to future-proof your career, or simply curious about how AI is reshaping financial management, I hope you&rsquo;ll find value in this series.</p>
<p>Next week, I&rsquo;ll publish the first full post in the series: &ldquo;AI in Finance: Separating Hype from Reality,&rdquo; where we&rsquo;ll explore the current state of AI in finance departments and develop a framework for evaluating AI claims from vendors.</p>
<p>Until then, I&rsquo;d love to hear from you: What aspects of AI in finance are you most curious about? What challenges are you facing in your own organization? Drop a comment below or reach out directly.</p>
<p>Here&rsquo;s to learning together!</p>
]]></content:encoded></item><item><title>Practical AI Use Cases in Finance Departments</title><link>https://michaelbrunger.com/practical-ai-use-cases-finance-departments/</link><pubDate>Sat, 12 Jul 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/practical-ai-use-cases-finance-departments/</guid><description>Detailed case studies of successful AI implementations across treasury, financial close, FP&amp;amp;A, tax, and other finance functions.</description></item><item><title>AI in Finance: Separating Hype from Reality</title><link>https://michaelbrunger.com/ai-finance-separating-hype-reality/</link><pubDate>Thu, 10 Jul 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/ai-finance-separating-hype-reality/</guid><description>Learn to distinguish between realistic AI applications in finance and overhyped claims, with practical frameworks for finance leaders to evaluate AI solutions.</description><content:encoded><![CDATA[<h1 id="ai-in-finance-separating-hype-from-reality">AI in Finance: Separating Hype from Reality</h1>
<p><em>This is the first installment in my series &ldquo;Financial Leadership in the AI Era.&rdquo; If you&rsquo;re new here, check out the <a href="link-to-intro">introduction post</a> to learn what this series is all about.</em></p>
<h2 id="the-current-state-of-ai-in-finance-departments">The Current State of AI in Finance Departments</h2>
<p>Three weeks into my new role as a finance manager, I&rsquo;ve been cataloging every vendor pitch that mentions AI, machine learning, or automation. The result? A spreadsheet with 23 different solutions, all promising to revolutionize our finance function through the power of artificial intelligence.</p>
<p>But when I dig deeper into these offerings, a familiar pattern emerges: what&rsquo;s marketed as &ldquo;AI&rdquo; often spans a spectrum from simple rules-based automation to genuine machine learning applications. This disconnect between marketing and reality isn&rsquo;t unique to my experience.</p>
<p>According to Gartner&rsquo;s 2024 research, while 84% of finance organizations report implementing or planning to implement AI technologies, only 27% report achieving significant business outcomes from these implementations (Gartner, 2024). This gap between adoption and realized value suggests many finance teams are struggling to separate AI hype from reality.</p>
<h2 id="common-misconceptions-about-ai-capabilities-in-finance">Common Misconceptions About AI Capabilities in Finance</h2>
<p>Before we can effectively implement AI in finance, we need to clear up some persistent misconceptions:</p>
<h3 id="misconception-1-ai-will-replace-finance-professionals">Misconception #1: AI will replace finance professionals</h3>
<p><strong>Reality</strong>: The evidence suggests otherwise. A 2023 study by Deloitte found that organizations successfully implementing AI in finance experienced a shift in roles rather than elimination—with 67% of finance professionals spending more time on analysis and decision support after AI implementation, compared to 31% before (Deloitte, 2023).</p>
<p>In my conversations with other finance leaders, the consensus is clear: AI excels at processing transactions, identifying patterns, and generating insights, but human judgment remains essential for strategic decision-making and stakeholder communication.</p>
<h3 id="misconception-2-ai-implementation-is-primarily-a-technology-challenge">Misconception #2: AI implementation is primarily a technology challenge</h3>
<p><strong>Reality</strong>: In my own department&rsquo;s experimentation with AP automation, I&rsquo;ve found that technical integration represents only about 30% of the implementation challenge. The remaining 70% involves process redesign, change management, and data governance.</p>
<p>This matches findings from McKinsey, which reports that successful AI implementations in finance dedicate 40-50% of project resources to organizational change management (McKinsey, 2024).</p>
<h3 id="misconception-3-ai-solutions-work-effectively-out-of-the-box">Misconception #3: AI solutions work effectively out of the box</h3>
<p><strong>Reality</strong>: Even the most advanced AI systems require significant training and customization to deliver value in finance. A 2023 survey by the Association of Finance Professionals found that finance departments spent an average of 6-9 months training and refining AI systems before achieving reliable performance (AFP, 2023).</p>
<h2 id="what-ai-can-and-cannot-do-today-in-finance">What AI Can and Cannot Do Today in Finance</h2>
<p>To make informed decisions about AI implementation, finance leaders need a realistic understanding of current capabilities:</p>
<h3 id="what-ai-can-do-today">What AI Can Do Today:</h3>
<ol>
<li>
<p><strong>Automate routine transaction processing</strong>: AI-powered systems can effectively automate up to 80% of accounts payable and receivable processes, according to research from Ardent Partners (2023).</p>
</li>
<li>
<p><strong>Enhance fraud detection</strong>: Machine learning models can identify unusual patterns that might indicate fraud with greater accuracy than rule-based systems. JP Morgan&rsquo;s COiN platform reportedly reviews documents in seconds that would take 360,000 hours manually (JP Morgan, 2023).</p>
</li>
<li>
<p><strong>Improve forecasting accuracy</strong>: In a controlled study by the International Institute of Forecasters, machine learning forecasting models reduced error rates by 15-30% compared to traditional methods for certain financial metrics (IIF, 2024).</p>
</li>
<li>
<p><strong>Streamline document processing</strong>: Natural language processing can extract key information from unstructured documents with 85-95% accuracy, dramatically reducing manual review time (ACCA Global, 2023).</p>
</li>
</ol>
<h3 id="what-ai-cannot-yet-reliably-do">What AI Cannot (Yet) Reliably Do:</h3>
<ol>
<li>
<p><strong>Make strategic financial decisions</strong>: While AI can provide decision support, it cannot replace human judgment in complex, high-stakes financial decisions.</p>
</li>
<li>
<p><strong>Adapt quickly to major economic shifts</strong>: Most AI models struggle when economic conditions change dramatically from their training data.</p>
</li>
<li>
<p><strong>Explain its reasoning fully</strong>: Despite advances in explainable AI, many financial machine learning models remain &ldquo;black boxes,&rdquo; creating challenges for governance and compliance.</p>
</li>
<li>
<p><strong>Manage stakeholder relationships</strong>: The human elements of finance—building trust, negotiating, and communicating difficult messages—remain beyond AI&rsquo;s capabilities.</p>
</li>
</ol>
<h2 id="case-studies-success-vs-hype">Case Studies: Success vs. Hype</h2>
<h3 id="success-story-progressive-automation-at-unilever">Success Story: Progressive Automation at Unilever</h3>
<p>Unilever&rsquo;s finance function demonstrates what realistic, value-driven AI implementation looks like. Rather than pursuing a comprehensive &ldquo;finance transformation,&rdquo; Unilever implemented targeted AI solutions in accounts payable, forecasting, and financial controls.</p>
<p>Their approach focused on specific pain points, with each implementation following a consistent pattern:</p>
<ul>
<li>Start with a narrow use case</li>
<li>Measure baseline performance</li>
<li>Run controlled pilots</li>
<li>Scale gradually with continuous measurement</li>
</ul>
<p>After three years of this targeted approach, Unilever reported a 40% reduction in manual transactions and a 20% improvement in forecasting accuracy (Unilever Annual Report, 2023).</p>
<h3 id="hype-example-the-ai-financial-transformation-that-wasnt">Hype Example: The &ldquo;AI Financial Transformation&rdquo; That Wasn&rsquo;t</h3>
<p>In contrast, a Fortune 500 company (unnamed in the Harvard Business Review case study) invested $15 million in a comprehensive AI-powered finance transformation. Two years later, the project was scaled back after delivering only marginal improvements.</p>
<p>The post-mortem analysis identified several cautionary lessons:</p>
<ul>
<li>The project attempted to simultaneously transform too many finance processes</li>
<li>Baseline metrics were not established before implementation</li>
<li>The solution relied heavily on &ldquo;perfect&rdquo; data that didn&rsquo;t exist in the organization</li>
<li>The team overestimated the AI&rsquo;s ability to handle exceptions and edge cases (Harvard Business Review, 2023)</li>
</ul>
<h2 id="a-framework-for-evaluating-ai-claims-from-vendors">A Framework for Evaluating AI Claims from Vendors</h2>
<p>Based on my research and early experiences evaluating AI solutions, I&rsquo;ve developed a preliminary framework for assessing vendor claims:</p>
<h3 id="the-5-question-ai-reality-check">The 5-Question AI Reality Check</h3>
<ol>
<li>
<p><strong>Can you explain exactly how your AI works in non-technical terms?</strong><br>
<em>Red flag: Vague explanations that rely heavily on buzzwords</em></p>
</li>
<li>
<p><strong>What specific data does your solution require, and what is the minimum quality threshold?</strong><br>
<em>Red flag: Claims that the solution works with &ldquo;any data&rdquo; regardless of quality</em></p>
</li>
<li>
<p><strong>What percentage of the process will still require human intervention?</strong><br>
<em>Red flag: Promises of 100% automation or unclear answers</em></p>
</li>
<li>
<p><strong>Can you provide before-and-after metrics from similar implementations?</strong><br>
<em>Red flag: Case studies without specific, measurable outcomes</em></p>
</li>
<li>
<p><strong>What&rsquo;s your approach to exceptions and edge cases?</strong><br>
<em>Red flag: Dismissing edge cases as &ldquo;rare&rdquo; or &ldquo;not significant&rdquo;</em></p>
</li>
</ol>
<p>In applying this framework at my company, we&rsquo;ve already eliminated three potential &ldquo;AI&rdquo; solutions that, upon closer examination, offered little beyond basic automation rebranded as artificial intelligence.</p>
<h2 id="practical-first-steps-for-finance-leaders">Practical First Steps for Finance Leaders</h2>
<p>If you&rsquo;re a finance leader beginning your AI journey, here are some practical steps based on my experience and research:</p>
<ol>
<li>
<p><strong>Audit your current processes</strong> to identify pain points where AI might add value, focusing on high-volume, rule-based activities with clean data.</p>
</li>
<li>
<p><strong>Start small with a pilot</strong> in a non-critical process area, establishing clear success metrics before beginning.</p>
</li>
<li>
<p><strong>Invest in data quality</strong> as a foundation for any AI implementation. According to IBM, organizations spend 40-60% of their AI project time on data preparation (IBM, 2023).</p>
</li>
<li>
<p><strong>Build internal knowledge</strong> by identifying team members with aptitude and interest in AI, and supporting their learning and experimentation.</p>
</li>
<li>
<p><strong>Create an AI evaluation committee</strong> with representatives from finance, IT, and business units to assess potential solutions.</p>
</li>
</ol>
<h2 id="my-learning-so-far">My Learning So Far</h2>
<p>Three weeks into exploring AI for our finance function, my biggest realization is that effective implementation isn&rsquo;t primarily about technology—it&rsquo;s about clearly defining problems worth solving. The finance teams seeing the most success aren&rsquo;t those with the most advanced AI, but those who have identified specific, measurable process pain points where AI can deliver tangible value.</p>
<p>In my next post, I&rsquo;ll explore &ldquo;Building Your Finance Team&rsquo;s AI Literacy,&rdquo; sharing the curriculum I&rsquo;m developing to help my team understand and engage with AI opportunities. I&rsquo;ll cover essential concepts every finance professional should understand, practical training approaches, and how to assess your team&rsquo;s current AI readiness.</p>
<h2 id="your-turn">Your Turn</h2>
<p>I&rsquo;d love to hear about your experiences with AI in finance:</p>
<ul>
<li>What AI solutions have you implemented or evaluated in your finance function?</li>
<li>Which claims from vendors have you found to be exaggerated?</li>
<li>What criteria do you use to separate genuine AI value from hype?</li>
</ul>
<p>Share your thoughts in the comments below or reach out directly.</p>
<hr>
<h2 id="sources">Sources</h2>
<ul>
<li>Association of Finance Professionals. (2023). <em>AI Implementation in Treasury and Finance Survey</em>. AFP.</li>
<li>Ardent Partners. (2023). <em>The State of Accounts Payable Automation</em>. Ardent Partners Research.</li>
<li>Deloitte. (2023). <em>Finance in a Digital World: CFO Insights</em>. Deloitte LLP.</li>
<li>Gartner. (2024). <em>Finance Technology Adoption Survey</em>. Gartner Research.</li>
<li>Harvard Business Review. (2023). <em>Why AI Implementations Fail in Finance Functions</em>. HBR Case Study.</li>
<li>IBM. (2023). <em>The AI Ladder: Accelerating the Journey to AI</em>. IBM Institute for Business Value.</li>
<li>International Institute of Forecasters. (2024). <em>Machine Learning vs. Traditional Forecasting Methods: A Comparative Analysis</em>. IIF Research.</li>
<li>JP Morgan Chase. (2023). <em>Annual Technology Review</em>. JP Morgan Chase.</li>
<li>McKinsey &amp; Company. (2024). <em>AI Adoption in Finance: Lessons from the Field</em>. McKinsey Digital.</li>
<li>Unilever. (2023). <em>Annual Report and Accounts</em>. Unilever PLC.</li>
<li>ACCA Global. (2023). <em>Machine Learning in Finance: Current Applications and Future Trends</em>. ACCA Research.</li>
</ul>
]]></content:encoded></item><item><title>Future Skills for Finance Leaders in an AI World</title><link>https://michaelbrunger.com/future-skills-finance-leaders-ai-world/</link><pubDate>Sat, 05 Jul 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/future-skills-finance-leaders-ai-world/</guid><description>Explore the evolving skill profile for finance professionals as AI transforms the industry, with strategies for future-proofing your career.</description></item><item><title>Measuring ROI on AI Investments in Finance</title><link>https://michaelbrunger.com/measuring-roi-ai-investments-finance/</link><pubDate>Sat, 28 Jun 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/measuring-roi-ai-investments-finance/</guid><description>Comprehensive frameworks for tracking and measuring the return on investment from AI implementations in finance departments.</description></item><item><title>Cost-Benefit Analysis of AI Solutions for Finance</title><link>https://michaelbrunger.com/cost-benefit-analysis-ai-solutions-finance/</link><pubDate>Sat, 21 Jun 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/cost-benefit-analysis-ai-solutions-finance/</guid><description>A structured approach to evaluating potential ROI and hidden costs of AI investments for finance functions, with practical business case templates.</description></item><item><title>Change Management for AI Adoption in Finance</title><link>https://michaelbrunger.com/change-management-ai-adoption-finance/</link><pubDate>Sat, 14 Jun 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/change-management-ai-adoption-finance/</guid><description>Strategies to overcome resistance and successfully manage the organizational change required for AI implementation in finance teams.</description></item><item><title>Implementing AI in Finance Operations</title><link>https://michaelbrunger.com/implementing-ai-finance-operations/</link><pubDate>Sat, 07 Jun 2025 09:00:00 -0500</pubDate><guid>https://michaelbrunger.com/implementing-ai-finance-operations/</guid><description>Practical guidance on deploying AI solutions across finance operations, from accounts payable to fraud detection and compliance.</description></item></channel></rss>